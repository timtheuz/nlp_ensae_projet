{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pos_label=1 is not a valid label. It should be one of ['femme', 'homme']",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 55>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;66;03m# Calculate evaluation metrics\u001B[39;00m\n\u001B[1;32m     69\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m accuracy_score(y_test, y_pred)\n\u001B[0;32m---> 70\u001B[0m precision \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbinary\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     71\u001B[0m recall \u001B[38;5;241m=\u001B[39m recall_score(y_test, y_pred, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     72\u001B[0m f1 \u001B[38;5;241m=\u001B[39m f1_score(y_test, y_pred, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1757\u001B[0m, in \u001B[0;36mprecision_score\u001B[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1628\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprecision_score\u001B[39m(\n\u001B[1;32m   1629\u001B[0m     y_true,\n\u001B[1;32m   1630\u001B[0m     y_pred,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1636\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1637\u001B[0m ):\n\u001B[1;32m   1638\u001B[0m     \u001B[38;5;124;03m\"\"\"Compute the precision.\u001B[39;00m\n\u001B[1;32m   1639\u001B[0m \n\u001B[1;32m   1640\u001B[0m \u001B[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1755\u001B[0m \u001B[38;5;124;03m    array([0.5, 1. , 1. ])\u001B[39;00m\n\u001B[1;32m   1756\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1757\u001B[0m     p, _, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_recall_fscore_support\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1758\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1759\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1760\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1761\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1762\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1763\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwarn_for\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprecision\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1764\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1765\u001B[0m \u001B[43m        \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1766\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1767\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1544\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support\u001B[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1542\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m beta \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1543\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbeta should be >=0 in the F-beta score\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1544\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[43m_check_set_wise_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1546\u001B[0m \u001B[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001B[39;00m\n\u001B[1;32m   1547\u001B[0m samplewise \u001B[38;5;241m=\u001B[39m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1356\u001B[0m, in \u001B[0;36m_check_set_wise_labels\u001B[0;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[1;32m   1354\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m pos_label \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m present_labels:\n\u001B[1;32m   1355\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(present_labels) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m-> 1356\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1357\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpos_label=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpos_label\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not a valid label. It \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1358\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshould be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpresent_labels\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1359\u001B[0m             )\n\u001B[1;32m   1360\u001B[0m     labels \u001B[38;5;241m=\u001B[39m [pos_label]\n\u001B[1;32m   1361\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: pos_label=1 is not a valid label. It should be one of ['femme', 'homme']"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "#from lightgbm import LGBMClassifier\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('transcriptions_with_sex.csv')\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = df['groundtruth']\n",
    "y = df['sex']\n",
    "\n",
    "# Train-test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define transformers for different feature types\n",
    "surname_vectorizer = TfidfVectorizer()\n",
    "firstname_vectorizer = TfidfVectorizer()\n",
    "occupation_encoder = OneHotEncoder()\n",
    "patron_encoder = OneHotEncoder()\n",
    "age_scaler = StandardScaler()\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'XGBoost': XGBClassifier()\n",
    "    #'LightGBM': LGBMClassifier()\n",
    "}\n",
    "\n",
    "# Define results dataframe\n",
    "results_df = pd.DataFrame(columns=['Vectorizer', 'Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'])\n",
    "\n",
    "# Iterate over vectorization techniques\n",
    "vectorizers = {\n",
    "    'Surname': surname_vectorizer,\n",
    "    'Firstname': firstname_vectorizer\n",
    "}\n",
    "\n",
    "for vec_name, vectorizer in vectorizers.items():\n",
    "    # Fit and transform vectorizer on training data\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    # Iterate over models\n",
    "    for model_name, model in models.items():\n",
    "        # Fit model on vectorized data\n",
    "        model.fit(X_train_vec, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test_vec)\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='binary')\n",
    "        recall = recall_score(y_test, y_pred, average='binary')\n",
    "        f1 = f1_score(y_test, y_pred, average='binary')\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "        # Append results to dataframe\n",
    "        results_df = results_df.append({'Vectorizer': vec_name,\n",
    "                                        'Model': model_name,\n",
    "                                        'Accuracy': accuracy,\n",
    "                                        'Precision': precision,\n",
    "                                        'Recall': recall,\n",
    "                                        'F1-Score': f1,\n",
    "                                        'ROC-AUC': roc_auc}, ignore_index=True)\n",
    "\n",
    "# Display results dataframe\n",
    "print(\"Results for Surname and Firstname Vectorization:\")\n",
    "display(results_df)\n",
    "\n",
    "# Reset results dataframe for occupation and patron link\n",
    "results_df = pd.DataFrame(columns=['Vectorizer', 'Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'])\n",
    "\n",
    "# Fit and transform one-hot encoders for occupation and patron link\n",
    "X_train_occ = occupation_encoder.fit_transform(X_train[['occupation']])\n",
    "X_test_occ = occupation_encoder.transform(X_test[['occupation']])\n",
    "\n",
    "X_train_patron = patron_encoder.fit_transform(X_train[['patron_link']])\n",
    "X_test_patron = patron_encoder.transform(X_test[['patron_link']])\n",
    "\n",
    "# Concatenate numerical age features\n",
    "X_train_age = age_scaler.fit_transform(X_train[['age']])\n",
    "X_test_age = age_scaler.transform(X_test[['age']])\n",
    "\n",
    "# Concatenate all features\n",
    "X_train_final = np.concatenate([X_train_occ.toarray(), X_train_patron.toarray(), X_train_age], axis=1)\n",
    "X_test_final = np.concatenate([X_test_occ.toarray(), X_test_patron.toarray(), X_test_age], axis=1)\n",
    "\n",
    "# Iterate over models for occupation and patron link\n",
    "for model_name, model in models.items():\n",
    "    # Fit model on concatenated data\n",
    "    model.fit(X_train_final, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_final)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # Append results to dataframe\n",
    "    results_df = results_df.append({'Vectorizer': 'Occupation and Patron Link',\n",
    "                                    'Model': model_name,\n",
    "                                    'Accuracy': accuracy,\n",
    "                                    'Precision': precision,\n",
    "                                    'Recall': recall,\n",
    "                                    'F1-Score': f1,\n",
    "                                    'ROC-AUC': roc_auc}, ignore_index=True)\n",
    "\n",
    "# Display results dataframe\n",
    "print(\"\\nResults for Occupation and Patron Link Vectorization:\")\n",
    "display(results_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
